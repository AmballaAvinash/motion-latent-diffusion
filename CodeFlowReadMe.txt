datasets    - humanml3d: requires some effort to construct the dataset    - kitml: easy download. Convert .rar files to folder configs: defualt argumnets    - assets: path configs    - config_mld_humanml3d.yaml: human ml 3d training configs    - config_mld_kitml.yaml:     - config_GAN_kitml.yaml: changer here the model_type GANprepare: contains sh files to download the pretrained modelstrain.py  -> file in which loading VAE, Diffusion model and training happening. test.py -> testing and calculating the evaluation metrics    from mld.data.get_data import get_datasets   ->datasets    from mld.config import parse_args  -> training arguments     from mld.models.get_model import get_model  -> models        from mld.callback import ProgressLogger  -> Progress logger    from mld.utils.logger import create_logger -> training logging  mld    - callback.progress -> progress loader    - config.py: argument parser. Default arguments in configs folders        phase = [train, test, demo, render]    - data: get_data.get_datasets    - launch:     - models:         get_model.get_model        model_type: base.py: base pytorch lighting module, mld.py, gan.py         architectures: define architectures        losses:        metrics:     - render:     - tools:    - transforms: transformation on 3D data.     - utils: logger.create_logger        render.py -> visulaize motions using blenderdemo    - example.txt: text input for testing    demo.py - loading the trained models and showing demo (text to motion) Scripts -> ### Ready to train VAE modelPlease first check the parameters in `configs/config_vae_humanml3d.yaml`, e.g. `NAME`,`DEBUG`.Then, run the following command:```python -m train --cfg configs/config_vae_kitml.yaml --cfg_assets configs/assets.yaml --batch_size 64 --nodebugpython -m train --cfg configs/config_vae_humanml3d.yaml --cfg_assets configs/assets.yaml --batch_size 64 --nodebug```### Ready to train MLD modelPlease update the parameters in `configs/config_mld_kitml.yaml`, e.g. `NAME`,`DEBUG`,`PRETRAINED_VAE` (change to your `latest ckpt model path` in previous step)Then, run the following command:```python -m train --cfg configs/config_mld_kitml.yaml --cfg_assets configs/assets.yaml --batch_size 64 --nodebugpython -m train --cfg configs/config_GAN_kitml.yaml --cfg_assets configs/assets.yaml --batch_size 64 --nodebug```### 3. Evaluate the modelPlease first put the tained model checkpoint path to `TEST.CHECKPOINT` in `configs/config_mld_humanml3d.yaml`.Then, run the following command:```python -m test --cfg configs/config_mld_kitml.yaml --cfg_assets configs/assets.yamlpython -m test --cfg configs/config_GAN_kitml.yaml --cfg_assets configs/assets.yaml```4. Demo python demo.py --cfg configs/config_GAN_kitml.yaml --cfg_assets ./configs/assets.yaml --example ./demo/example.txtNotations:1. a2m: action to motion2. T2m : text to motion (current focus)Request muliple GPUSLOss in GAN: 